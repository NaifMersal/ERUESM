{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/facenet_pytorch/models/mtcnn.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path)\n",
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/facenet_pytorch/models/mtcnn.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path)\n",
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/facenet_pytorch/models/mtcnn.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 2880/2880 [00:00<00:00, 60397.68it/s]\n",
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/facenet_pytorch/models/mtcnn.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path)\n",
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/facenet_pytorch/models/mtcnn.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path)\n",
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/facenet_pytorch/models/mtcnn.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(state_dict_path)\n",
      "Processing videos: 100%|██████████| 120/120 [01:13<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.helpers import setup_env\n",
    "\n",
    "# If running locally, this will download dataset (make sure you have at \n",
    "# least 2 Gb of space on your hard drive)\n",
    "setup_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.helpers import train_test_split\n",
    "df = pd.read_csv(\"data/metadata.csv\")\n",
    "df = df[df['video_id'].apply(lambda x:x[:2]!='02')& (df['dataset']=='RAVDESS')].reset_index(drop=True)\n",
    "# Stratified split\n",
    "train_df, valid_df = train_test_split(\n",
    "        df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fearful', 'sad', 'disgust', 'surprised', 'happy', 'angry', 'calm',\n",
       "       'neutral'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stratify_on']=df['dataset']+'_'+df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         RAVDESS_fearful\n",
       "1             RAVDESS_sad\n",
       "2             RAVDESS_sad\n",
       "3         RAVDESS_disgust\n",
       "4       RAVDESS_surprised\n",
       "              ...        \n",
       "1435         RAVDESS_calm\n",
       "1436         RAVDESS_calm\n",
       "1437      RAVDESS_disgust\n",
       "1438        RAVDESS_angry\n",
       "1439      RAVDESS_fearful\n",
       "Name: stratify_on, Length: 1440, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stratify_on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad',\n",
       "       'surprised'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'frame_dir', 'audio_path', 'emotion', 'target', 'dataset'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-22 22:21:18.539832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-22 22:21:19.207056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# imports\n",
    "from src.data import create_dataloaders \n",
    "from src.train import optimize\n",
    "from src.helpers import load_model, replace_insatance\n",
    "import torch.nn.functional as F\n",
    "import src.models as im_modesl\n",
    "from torch.optim import lr_scheduler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1184171671845911,\n",
       " 0.1184171671845911,\n",
       " 0.12094593283936474,\n",
       " 0.11924238390842237,\n",
       " 0.11780937617133798,\n",
       " 0.11780937617133798,\n",
       " 0.11780937617133798,\n",
       " 0.11801093213764494,\n",
       " 0.11924238390842237,\n",
       " 0.11780937617133798]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique classes and their counts\n",
    "stratify_on =train_df['emotion'].to_numpy()\n",
    "unique_classes, class_counts = np.unique(stratify_on, return_counts=True)\n",
    "\n",
    "# Calculate class weights (inverse frequency)\n",
    "n_samples = len(stratify_on)\n",
    "class_weights = {}\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    # Weight = total_samples / (num_classes * count_per_class)\n",
    "    class_weights[cls] = n_samples / (len(unique_classes) * count)**0.5\n",
    "\n",
    "# Create sample weights array\n",
    "sample_weights = [class_weights[t]/sum(class_weights.values()) for t in stratify_on]\n",
    "sample_weights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1228, 0.1209, 0.1210, 0.1225, 0.1217, 0.1496, 0.1212, 0.1204],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights= torch.tensor([len(df)/(class_counts[i]*len(class_counts))**0.3 for i in range(len(class_counts)) ],dtype=torch.float32 ,device='cuda')\n",
    "class_weights/=class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainnig parameters\n",
    "print_model=0\n",
    "batch_size = 16  # size of the minibatch for stochastic gradient descent (or Adam)\n",
    "num_epochs = 20    # number of epochs for training\n",
    "num_classes = len(df['emotion'].cat.categories)      # number of classes. Do not change this\n",
    "learning_rate =0.001*(0.6)**2  # Learning rate for SGD (or Adam)\n",
    "weight_decay = 0.004     # regularization. Increase this to combat overfitting\n",
    "momentum=0.9 \n",
    "accumulation_steps=4\n",
    "checkpoints_loading_order = ['best', 'last']\n",
    "model_name= \"AuVi2LSTMModel\"\n",
    "suffix='base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 \tTraining Loss: 0.191873 \tValidation Loss: 0.384179\tTraining Acc@1: 99.583 \tValidation Acc@1: 92.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                         | 0/135 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(train_df), replacement=True, generator=None)\n",
    "\n",
    "data_loaders = create_dataloaders(batch_size=batch_size, num_workers=8, sampler=sampler)\n",
    "torch.backends.cuda.matmul.allow_tf32=True\n",
    "torch.backends.cudnn.allow_tf32=True\n",
    "\n",
    "model = getattr(im_modesl, model_name)(num_classes=num_classes)\n",
    "# # initialize\n",
    "# def init_weights(m):\n",
    "#     if isinstance(m, torch.nn.Conv2d):\n",
    "#         torch.nn.init.orthogonal_(m.weight)\n",
    "\n",
    "# model.apply(init_weights)\n",
    "# Get the optimizer using get_optimizer and the model you just created, the learning rate,\n",
    "# the optimizer and the weight decay specified in the previous cel\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate,weight_decay=weight_decay,)#momentum=momentum\n",
    "\n",
    "\n",
    "#milestones=[5,9,12, *range(12,num_epochs,2)]\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.6, patience=1,threshold=1e-3,verbose=True)\n",
    "#scheduler = lr_scheduler.ExponentialLR(optimizer,gamma=0.7)\n",
    "\n",
    "def step(loss ,epoch=None):\n",
    "    scheduler.step(loss)\n",
    "\n",
    "def loss(output,target):\n",
    "    #target=F.one_hot(target, num_classes).float()\n",
    "    return F.cross_entropy(output, target,label_smoothing=0.03,weight=class_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s_epoch=load_model(model_name+suffix,model, checkpoints_loading_order)\n",
    "if print_model:\n",
    "    print(f\"model {model_name} has :{sum(p.numel() for p in model.parameters())/1e6} M parameters \")\n",
    "    print(f\"Effictive W>0.01 precentage: \")\n",
    "    print('\\n'.join('layer {} has : {}'.format(n,torch.sum(torch.abs(p)>0.01)/p.numel()) for n, p in model.named_parameters()))\n",
    "#replace_insatance(model,torch.nn.LeakyReLU, models.Swish())\n",
    "#print(model)\n",
    "\n",
    "optimize(\n",
    "    data_loaders,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    s_epoch=s_epoch,\n",
    "    n_epochs=num_epochs,\n",
    "    model_name=model_name+suffix,\n",
    "    step=step,\n",
    "    accumulation_steps=accumulation_steps,\n",
    "    run_logs=True,\n",
    "    interactive_tracking=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 22:46:06,448 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt: /home/naif/.cache/modelscope/hub/iic/emotion2vec_plus_base/model.pt\n",
      "init param, map: modality_encoders.AUDIO.extra_tokens from d2v_model.modality_encoders.AUDIO.extra_tokens in ckpt\n",
      "init param, map: modality_encoders.AUDIO.alibi_scale from d2v_model.modality_encoders.AUDIO.alibi_scale in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.weight from d2v_model.modality_encoders.AUDIO.project_features.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.bias from d2v_model.modality_encoders.AUDIO.project_features.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.weight from d2v_model.modality_encoders.AUDIO.project_features.2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.bias from d2v_model.modality_encoders.AUDIO.project_features.2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.weight from d2v_model.modality_encoders.AUDIO.context_encoder.norm.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.bias from d2v_model.modality_encoders.AUDIO.context_encoder.norm.bias in ckpt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, mapped: modality_encoders.AUDIO.decoder.proj.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, mapped: modality_encoders.AUDIO.decoder.proj.bias\n",
      "init param, map: blocks.0.norm1.weight from d2v_model.blocks.0.norm1.weight in ckpt\n",
      "init param, map: blocks.0.norm1.bias from d2v_model.blocks.0.norm1.bias in ckpt\n",
      "init param, map: blocks.0.attn.qkv.weight from d2v_model.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.0.attn.qkv.bias from d2v_model.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.0.attn.proj.weight from d2v_model.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: blocks.0.attn.proj.bias from d2v_model.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: blocks.0.norm2.weight from d2v_model.blocks.0.norm2.weight in ckpt\n",
      "init param, map: blocks.0.norm2.bias from d2v_model.blocks.0.norm2.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.weight from d2v_model.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.bias from d2v_model.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.weight from d2v_model.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.bias from d2v_model.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.1.norm1.weight from d2v_model.blocks.1.norm1.weight in ckpt\n",
      "init param, map: blocks.1.norm1.bias from d2v_model.blocks.1.norm1.bias in ckpt\n",
      "init param, map: blocks.1.attn.qkv.weight from d2v_model.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.1.attn.qkv.bias from d2v_model.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.1.attn.proj.weight from d2v_model.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: blocks.1.attn.proj.bias from d2v_model.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: blocks.1.norm2.weight from d2v_model.blocks.1.norm2.weight in ckpt\n",
      "init param, map: blocks.1.norm2.bias from d2v_model.blocks.1.norm2.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.weight from d2v_model.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.bias from d2v_model.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.weight from d2v_model.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.bias from d2v_model.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.2.norm1.weight from d2v_model.blocks.2.norm1.weight in ckpt\n",
      "init param, map: blocks.2.norm1.bias from d2v_model.blocks.2.norm1.bias in ckpt\n",
      "init param, map: blocks.2.attn.qkv.weight from d2v_model.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.2.attn.qkv.bias from d2v_model.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.2.attn.proj.weight from d2v_model.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: blocks.2.attn.proj.bias from d2v_model.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: blocks.2.norm2.weight from d2v_model.blocks.2.norm2.weight in ckpt\n",
      "init param, map: blocks.2.norm2.bias from d2v_model.blocks.2.norm2.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.weight from d2v_model.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.bias from d2v_model.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.weight from d2v_model.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.bias from d2v_model.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.3.norm1.weight from d2v_model.blocks.3.norm1.weight in ckpt\n",
      "init param, map: blocks.3.norm1.bias from d2v_model.blocks.3.norm1.bias in ckpt\n",
      "init param, map: blocks.3.attn.qkv.weight from d2v_model.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.3.attn.qkv.bias from d2v_model.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.3.attn.proj.weight from d2v_model.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: blocks.3.attn.proj.bias from d2v_model.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: blocks.3.norm2.weight from d2v_model.blocks.3.norm2.weight in ckpt\n",
      "init param, map: blocks.3.norm2.bias from d2v_model.blocks.3.norm2.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.weight from d2v_model.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.bias from d2v_model.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.weight from d2v_model.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.bias from d2v_model.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.4.norm1.weight from d2v_model.blocks.4.norm1.weight in ckpt\n",
      "init param, map: blocks.4.norm1.bias from d2v_model.blocks.4.norm1.bias in ckpt\n",
      "init param, map: blocks.4.attn.qkv.weight from d2v_model.blocks.4.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.4.attn.qkv.bias from d2v_model.blocks.4.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.4.attn.proj.weight from d2v_model.blocks.4.attn.proj.weight in ckpt\n",
      "init param, map: blocks.4.attn.proj.bias from d2v_model.blocks.4.attn.proj.bias in ckpt\n",
      "init param, map: blocks.4.norm2.weight from d2v_model.blocks.4.norm2.weight in ckpt\n",
      "init param, map: blocks.4.norm2.bias from d2v_model.blocks.4.norm2.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.weight from d2v_model.blocks.4.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.bias from d2v_model.blocks.4.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.weight from d2v_model.blocks.4.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.bias from d2v_model.blocks.4.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.5.norm1.weight from d2v_model.blocks.5.norm1.weight in ckpt\n",
      "init param, map: blocks.5.norm1.bias from d2v_model.blocks.5.norm1.bias in ckpt\n",
      "init param, map: blocks.5.attn.qkv.weight from d2v_model.blocks.5.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.5.attn.qkv.bias from d2v_model.blocks.5.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.5.attn.proj.weight from d2v_model.blocks.5.attn.proj.weight in ckpt\n",
      "init param, map: blocks.5.attn.proj.bias from d2v_model.blocks.5.attn.proj.bias in ckpt\n",
      "init param, map: blocks.5.norm2.weight from d2v_model.blocks.5.norm2.weight in ckpt\n",
      "init param, map: blocks.5.norm2.bias from d2v_model.blocks.5.norm2.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.weight from d2v_model.blocks.5.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.bias from d2v_model.blocks.5.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.weight from d2v_model.blocks.5.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.bias from d2v_model.blocks.5.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.6.norm1.weight from d2v_model.blocks.6.norm1.weight in ckpt\n",
      "init param, map: blocks.6.norm1.bias from d2v_model.blocks.6.norm1.bias in ckpt\n",
      "init param, map: blocks.6.attn.qkv.weight from d2v_model.blocks.6.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.6.attn.qkv.bias from d2v_model.blocks.6.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.6.attn.proj.weight from d2v_model.blocks.6.attn.proj.weight in ckpt\n",
      "init param, map: blocks.6.attn.proj.bias from d2v_model.blocks.6.attn.proj.bias in ckpt\n",
      "init param, map: blocks.6.norm2.weight from d2v_model.blocks.6.norm2.weight in ckpt\n",
      "init param, map: blocks.6.norm2.bias from d2v_model.blocks.6.norm2.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.weight from d2v_model.blocks.6.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.bias from d2v_model.blocks.6.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.weight from d2v_model.blocks.6.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.bias from d2v_model.blocks.6.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.7.norm1.weight from d2v_model.blocks.7.norm1.weight in ckpt\n",
      "init param, map: blocks.7.norm1.bias from d2v_model.blocks.7.norm1.bias in ckpt\n",
      "init param, map: blocks.7.attn.qkv.weight from d2v_model.blocks.7.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.7.attn.qkv.bias from d2v_model.blocks.7.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.7.attn.proj.weight from d2v_model.blocks.7.attn.proj.weight in ckpt\n",
      "init param, map: blocks.7.attn.proj.bias from d2v_model.blocks.7.attn.proj.bias in ckpt\n",
      "init param, map: blocks.7.norm2.weight from d2v_model.blocks.7.norm2.weight in ckpt\n",
      "init param, map: blocks.7.norm2.bias from d2v_model.blocks.7.norm2.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.weight from d2v_model.blocks.7.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.bias from d2v_model.blocks.7.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.weight from d2v_model.blocks.7.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.bias from d2v_model.blocks.7.mlp.fc2.bias in ckpt\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 2 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 36/36 [00:30<00:00,  1.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.410528038110998, [94.09722222222223])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.train import valid_one_epoch\n",
    "model = getattr(im_modesl, model_name)(num_classes=num_classes).cuda()\n",
    "\n",
    "loss =lambda output,target: F.cross_entropy(output, target,label_smoothing=0.03, weight=class_weights)\n",
    "\n",
    "load_model(model_name+suffix,model, checkpoints_loading_order)\n",
    "valid_one_epoch(data_loaders['valid'], model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 07:07:20.798240: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 07:07:21.400397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.train import valid_one_epoch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.train import to_device\n",
    "from src.helpers import seed, load_model, train_test_split\n",
    "from src.data import create_dataloaders\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, Literal\n",
    "\n",
    "\n",
    "class AuViLSTMModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 5,\n",
    "        mode: Literal[\"audio\", \"visual\", \"both\"] = \"visual\",\n",
    "        hidden_sizes: Dict = {\"audio\":384, \"visual\":384 },\n",
    "        rnn_num_layers: int = 2,\n",
    "        backbone_feat_size: int = 768\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Simplified AuViLSTMModel for emotion recognition.\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of emotion classes\n",
    "            mode: Training mode (\"audio\", \"visual\", or \"both\")\n",
    "            rnn_hidden_size: Hidden size for LSTM layers\n",
    "            rnn_num_layers: Number of LSTM layers\n",
    "            backbone_feat_size: Feature size from backbone models\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Visual components\n",
    "        if mode in [\"visual\", \"both\"]:\n",
    "            \n",
    "            from transformers import AutoModelForImageClassification \n",
    "\n",
    "            self.v_backbone = AutoModelForImageClassification.from_pretrained(\n",
    "                \"dima806/facial_emotions_image_detection\"\n",
    "            )\n",
    "            self.v_backbone.classifier = torch.nn.Identity()  # Remove classifier\n",
    "            self.v_rnn = torch.nn.GRU(\n",
    "                input_size=backbone_feat_size,\n",
    "                hidden_size=hidden_sizes['visual'],\n",
    "                num_layers=rnn_num_layers,\n",
    "                batch_first=True\n",
    "            )\n",
    "            \n",
    "            # Freeze backbone\n",
    "            for param in self.v_backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Audio components\n",
    "        if mode in [\"audio\", \"both\"]:\n",
    "            from funasr import AutoModel\n",
    "            audio_model = AutoModel(model=\"iic/emotion2vec_plus_base\")\n",
    "            self.a_backbone = audio_model.model\n",
    "            self.a_rnn = torch.load(\"audio/GRU.pt\")\n",
    "            \n",
    "            # Freeze backbone\n",
    "            for param in self.a_backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Final classifier\n",
    "        input_size = hidden_sizes[mode] if mode != \"both\" else hidden_sizes[\"visual\"]+hidden_sizes[\"audio\"]\n",
    "        self.classifier = torch.nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Args:\n",
    "            batch: Dictionary containing 'frames' and/or 'audio' depending on mode\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Classification logits\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Process visual input\n",
    "        if self.mode in [\"visual\", \"both\"]:\n",
    "            frames = batch['frames']\n",
    "            batch_size = frames.shape[0]\n",
    "            seq_len = frames.shape[1]\n",
    "            \n",
    "            # Reshape for backbone\n",
    "            frames = frames.view(-1, *frames.shape[-3:])\n",
    "            \n",
    "            # Extract features\n",
    "            with torch.inference_mode():\n",
    "                visual_feats = self.v_backbone(frames).logits\n",
    "            \n",
    "            # Reshape back to sequence\n",
    "            visual_feats = visual_feats.view(batch_size, seq_len, -1)\n",
    "            \n",
    "            # Process through GRU\n",
    "            _, h_n = self.v_rnn(visual_feats)\n",
    "            features.append(h_n[-1])  # Take last layer's hidden state\n",
    "            # features.append(visual_feats.mean(dim=1))\n",
    "        \n",
    "        # Process audio input\n",
    "        if self.mode in [\"audio\", \"both\"]:\n",
    "            audio = batch['audio'].squeeze(1)  # Remove channel dimension\n",
    "            \n",
    "            # Normalize audio\n",
    "            audio = torch.nn.functional.layer_norm(audio, [audio.shape[-1]])\n",
    "            \n",
    "            # Extract features\n",
    "            with torch.inference_mode():\n",
    "                audio_feats = self.a_backbone.extract_features(audio)['x']\n",
    "            \n",
    "            # Process through GRU\n",
    "            _, h_n = self.a_rnn(audio_feats)\n",
    "            features.append(h_n[-1])  # Take last layer's hidden state\n",
    "        \n",
    "        # Combine features and classify\n",
    "        combined_features = torch.cat(features, dim=-1) if len(features) > 1 else features[0]\n",
    "        return self.classifier(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_predictions(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate model and return accuracies along with predictions and ground truths.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (unweighted_acc, weighted_acc, predictions, ground_truths)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_unweighted = 0\n",
    "    n_batches = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = to_device(inputs, 'cuda')\n",
    "            targets = to_device(targets, 'cuda')\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            correct = (preds == targets).float()\n",
    "            \n",
    "            # Unweighted accuracy\n",
    "            unweighted_acc = correct.mean().item()\n",
    "            \n",
    "            \n",
    "            total_unweighted += unweighted_acc\n",
    "\n",
    "            n_batches += 1\n",
    "    \n",
    "    return (\n",
    "        total_unweighted / n_batches, \n",
    "        np.array(all_preds),\n",
    "        np.array(all_targets)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naif/projects/videoEmotionRecognition/src/helpers.py:521: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'{checkpoints_dir}/{loading_order[0]}_{model_name}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 28 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 30 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 30 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 30 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 29 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 30 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 27 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 30 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 28 number of epochs...\n",
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 30 number of epochs...\n"
     ]
    }
   ],
   "source": [
    "checkpoints_loading_order = ['best', 'last']\n",
    "results =[]\n",
    "df = pd.read_csv(\"data/metadata.csv\")\n",
    "df = df[(df['dataset']=='UJ_ACTORS')].reset_index(drop=True)\n",
    "df['stratify_on']=df['dataset']+'_'+df['emotion']\n",
    "\n",
    "model = AuViLSTMModel(num_classes=8, mode= 'visual').cuda()\n",
    "\n",
    "loss_fn =lambda output,target: F.cross_entropy(output, target,label_smoothing=0.03)\n",
    "for fold in range(5):\n",
    "    current_seed = seed + fold\n",
    "    torch.manual_seed(current_seed)\n",
    "    np.random.seed(current_seed)\n",
    "    \n",
    "    # Split data\n",
    "    train_fold, valid_fold = train_test_split(\n",
    "        df, test_size=0.2,\n",
    "        stratify=df['stratify_on'],\n",
    "        random_state=current_seed\n",
    "    )\n",
    "\n",
    "    model_name = f\"visual_fold{fold}\"\n",
    "    load_model(model_name,model,loading_order=checkpoints_loading_order, checkpoints_dir=\"experiments/20241130_235623_sequential_training/model_checkpoints\")\n",
    "\n",
    "    valid_loader = create_dataloaders(df, batch_size=1 , valid_df=valid_fold)['valid'] # we will use only valid_df\n",
    "    result =evaluate_model_with_predictions(model, valid_loader)\n",
    "    results.append([fold,\"best\", *result])\n",
    "\n",
    "    load_model(model_name,model,loading_order=checkpoints_loading_order[::-1], checkpoints_dir=\"experiments/20241130_235623_sequential_training/model_checkpoints\")\n",
    "    valid_loader = create_dataloaders(df, batch_size=1 , valid_df=valid_fold)['valid'] # we will use only valid_df\n",
    "    result =evaluate_model_with_predictions(model, valid_loader)\n",
    "    results.append([fold,\"best\", *result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  'best',\n",
       "  0.25,\n",
       "  array([1, 6, 1, 6, 6, 1, 1, 2, 1, 1, 3, 1, 1, 4, 4, 1, 1, 1, 6, 1, 1, 0,\n",
       "         4, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [0,\n",
       "  'best',\n",
       "  0.25,\n",
       "  array([1, 6, 1, 6, 6, 1, 1, 2, 1, 1, 3, 1, 1, 4, 4, 1, 1, 1, 6, 1, 1, 0,\n",
       "         4, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [1,\n",
       "  'best',\n",
       "  0.25,\n",
       "  array([1, 4, 0, 1, 6, 1, 1, 2, 1, 0, 0, 4, 1, 1, 4, 1, 1, 1, 6, 1, 1, 0,\n",
       "         1, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [1,\n",
       "  'best',\n",
       "  0.25,\n",
       "  array([1, 4, 0, 1, 6, 1, 1, 2, 1, 0, 0, 4, 1, 1, 4, 1, 1, 1, 6, 1, 1, 0,\n",
       "         1, 0]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [2,\n",
       "  'best',\n",
       "  0.08333333333333333,\n",
       "  array([1, 4, 1, 0, 0, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 6, 1, 3, 1, 1, 4,\n",
       "         1, 4]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [2,\n",
       "  'best',\n",
       "  0.08333333333333333,\n",
       "  array([1, 4, 1, 0, 0, 1, 1, 1, 1, 4, 1, 1, 1, 4, 1, 1, 6, 1, 3, 1, 1, 4,\n",
       "         1, 4]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [3,\n",
       "  'best',\n",
       "  0.125,\n",
       "  array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 0, 1, 4, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [3,\n",
       "  'best',\n",
       "  0.125,\n",
       "  array([1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 0, 1, 4, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [4,\n",
       "  'best',\n",
       "  0.20833333333333334,\n",
       "  array([1, 1, 2, 1, 1, 1, 4, 1, 1, 0, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 6, 1,\n",
       "         1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])],\n",
       " [4,\n",
       "  'best',\n",
       "  0.16666666666666666,\n",
       "  array([1, 1, 6, 1, 1, 1, 4, 1, 1, 0, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]),\n",
       "  array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7,\n",
       "         7, 7])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 04:16:06,177 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt: /home/naif/.cache/modelscope/hub/iic/emotion2vec_plus_base/model.pt\n",
      "init param, map: modality_encoders.AUDIO.extra_tokens from d2v_model.modality_encoders.AUDIO.extra_tokens in ckpt\n",
      "init param, map: modality_encoders.AUDIO.alibi_scale from d2v_model.modality_encoders.AUDIO.alibi_scale in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.weight from d2v_model.modality_encoders.AUDIO.project_features.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.bias from d2v_model.modality_encoders.AUDIO.project_features.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.weight from d2v_model.modality_encoders.AUDIO.project_features.2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.bias from d2v_model.modality_encoders.AUDIO.project_features.2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.weight from d2v_model.modality_encoders.AUDIO.context_encoder.norm.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.bias from d2v_model.modality_encoders.AUDIO.context_encoder.norm.bias in ckpt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, mapped: modality_encoders.AUDIO.decoder.proj.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, mapped: modality_encoders.AUDIO.decoder.proj.bias\n",
      "init param, map: blocks.0.norm1.weight from d2v_model.blocks.0.norm1.weight in ckpt\n",
      "init param, map: blocks.0.norm1.bias from d2v_model.blocks.0.norm1.bias in ckpt\n",
      "init param, map: blocks.0.attn.qkv.weight from d2v_model.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.0.attn.qkv.bias from d2v_model.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.0.attn.proj.weight from d2v_model.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: blocks.0.attn.proj.bias from d2v_model.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: blocks.0.norm2.weight from d2v_model.blocks.0.norm2.weight in ckpt\n",
      "init param, map: blocks.0.norm2.bias from d2v_model.blocks.0.norm2.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.weight from d2v_model.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.bias from d2v_model.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.weight from d2v_model.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.bias from d2v_model.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.1.norm1.weight from d2v_model.blocks.1.norm1.weight in ckpt\n",
      "init param, map: blocks.1.norm1.bias from d2v_model.blocks.1.norm1.bias in ckpt\n",
      "init param, map: blocks.1.attn.qkv.weight from d2v_model.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.1.attn.qkv.bias from d2v_model.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.1.attn.proj.weight from d2v_model.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: blocks.1.attn.proj.bias from d2v_model.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: blocks.1.norm2.weight from d2v_model.blocks.1.norm2.weight in ckpt\n",
      "init param, map: blocks.1.norm2.bias from d2v_model.blocks.1.norm2.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.weight from d2v_model.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.bias from d2v_model.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.weight from d2v_model.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.bias from d2v_model.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.2.norm1.weight from d2v_model.blocks.2.norm1.weight in ckpt\n",
      "init param, map: blocks.2.norm1.bias from d2v_model.blocks.2.norm1.bias in ckpt\n",
      "init param, map: blocks.2.attn.qkv.weight from d2v_model.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.2.attn.qkv.bias from d2v_model.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.2.attn.proj.weight from d2v_model.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: blocks.2.attn.proj.bias from d2v_model.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: blocks.2.norm2.weight from d2v_model.blocks.2.norm2.weight in ckpt\n",
      "init param, map: blocks.2.norm2.bias from d2v_model.blocks.2.norm2.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.weight from d2v_model.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.bias from d2v_model.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.weight from d2v_model.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.bias from d2v_model.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.3.norm1.weight from d2v_model.blocks.3.norm1.weight in ckpt\n",
      "init param, map: blocks.3.norm1.bias from d2v_model.blocks.3.norm1.bias in ckpt\n",
      "init param, map: blocks.3.attn.qkv.weight from d2v_model.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.3.attn.qkv.bias from d2v_model.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.3.attn.proj.weight from d2v_model.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: blocks.3.attn.proj.bias from d2v_model.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: blocks.3.norm2.weight from d2v_model.blocks.3.norm2.weight in ckpt\n",
      "init param, map: blocks.3.norm2.bias from d2v_model.blocks.3.norm2.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.weight from d2v_model.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.bias from d2v_model.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.weight from d2v_model.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.bias from d2v_model.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.4.norm1.weight from d2v_model.blocks.4.norm1.weight in ckpt\n",
      "init param, map: blocks.4.norm1.bias from d2v_model.blocks.4.norm1.bias in ckpt\n",
      "init param, map: blocks.4.attn.qkv.weight from d2v_model.blocks.4.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.4.attn.qkv.bias from d2v_model.blocks.4.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.4.attn.proj.weight from d2v_model.blocks.4.attn.proj.weight in ckpt\n",
      "init param, map: blocks.4.attn.proj.bias from d2v_model.blocks.4.attn.proj.bias in ckpt\n",
      "init param, map: blocks.4.norm2.weight from d2v_model.blocks.4.norm2.weight in ckpt\n",
      "init param, map: blocks.4.norm2.bias from d2v_model.blocks.4.norm2.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.weight from d2v_model.blocks.4.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.bias from d2v_model.blocks.4.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.weight from d2v_model.blocks.4.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.bias from d2v_model.blocks.4.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.5.norm1.weight from d2v_model.blocks.5.norm1.weight in ckpt\n",
      "init param, map: blocks.5.norm1.bias from d2v_model.blocks.5.norm1.bias in ckpt\n",
      "init param, map: blocks.5.attn.qkv.weight from d2v_model.blocks.5.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.5.attn.qkv.bias from d2v_model.blocks.5.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.5.attn.proj.weight from d2v_model.blocks.5.attn.proj.weight in ckpt\n",
      "init param, map: blocks.5.attn.proj.bias from d2v_model.blocks.5.attn.proj.bias in ckpt\n",
      "init param, map: blocks.5.norm2.weight from d2v_model.blocks.5.norm2.weight in ckpt\n",
      "init param, map: blocks.5.norm2.bias from d2v_model.blocks.5.norm2.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.weight from d2v_model.blocks.5.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.bias from d2v_model.blocks.5.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.weight from d2v_model.blocks.5.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.bias from d2v_model.blocks.5.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.6.norm1.weight from d2v_model.blocks.6.norm1.weight in ckpt\n",
      "init param, map: blocks.6.norm1.bias from d2v_model.blocks.6.norm1.bias in ckpt\n",
      "init param, map: blocks.6.attn.qkv.weight from d2v_model.blocks.6.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.6.attn.qkv.bias from d2v_model.blocks.6.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.6.attn.proj.weight from d2v_model.blocks.6.attn.proj.weight in ckpt\n",
      "init param, map: blocks.6.attn.proj.bias from d2v_model.blocks.6.attn.proj.bias in ckpt\n",
      "init param, map: blocks.6.norm2.weight from d2v_model.blocks.6.norm2.weight in ckpt\n",
      "init param, map: blocks.6.norm2.bias from d2v_model.blocks.6.norm2.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.weight from d2v_model.blocks.6.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.bias from d2v_model.blocks.6.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.weight from d2v_model.blocks.6.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.bias from d2v_model.blocks.6.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.7.norm1.weight from d2v_model.blocks.7.norm1.weight in ckpt\n",
      "init param, map: blocks.7.norm1.bias from d2v_model.blocks.7.norm1.bias in ckpt\n",
      "init param, map: blocks.7.attn.qkv.weight from d2v_model.blocks.7.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.7.attn.qkv.bias from d2v_model.blocks.7.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.7.attn.proj.weight from d2v_model.blocks.7.attn.proj.weight in ckpt\n",
      "init param, map: blocks.7.attn.proj.bias from d2v_model.blocks.7.attn.proj.bias in ckpt\n",
      "init param, map: blocks.7.norm2.weight from d2v_model.blocks.7.norm2.weight in ckpt\n",
      "init param, map: blocks.7.norm2.bias from d2v_model.blocks.7.norm2.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.weight from d2v_model.blocks.7.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.bias from d2v_model.blocks.7.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.weight from d2v_model.blocks.7.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.bias from d2v_model.blocks.7.mlp.fc2.bias in ckpt\n",
      "1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1335197/3016258471.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.a_rnn = torch.load(\"GRU.pt\")\n"
     ]
    }
   ],
   "source": [
    "model = AuViLSTMModel(num_classes=len(df['emotion'].cat.categories), mode= 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 06:40:16,216 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt: /home/naif/.cache/modelscope/hub/iic/emotion2vec_plus_base/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naif/miniconda3/envs/em2vec/lib/python3.8/site-packages/funasr/train_utils/load_pretrained_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  src_state = torch.load(path, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init param, map: modality_encoders.AUDIO.extra_tokens from d2v_model.modality_encoders.AUDIO.extra_tokens in ckpt\n",
      "init param, map: modality_encoders.AUDIO.alibi_scale from d2v_model.modality_encoders.AUDIO.alibi_scale in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.0.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.1.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.2.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.3.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.4.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.5.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias from d2v_model.modality_encoders.AUDIO.local_encoder.conv_layers.6.2.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.weight from d2v_model.modality_encoders.AUDIO.project_features.1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.1.bias from d2v_model.modality_encoders.AUDIO.project_features.1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.weight from d2v_model.modality_encoders.AUDIO.project_features.2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.project_features.2.bias from d2v_model.modality_encoders.AUDIO.project_features.2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.1.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.1.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.2.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.2.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.3.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.3.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.4.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.4.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.weight from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.relative_positional_encoder.5.0.bias from d2v_model.modality_encoders.AUDIO.relative_positional_encoder.5.0.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.norm2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias from d2v_model.modality_encoders.AUDIO.context_encoder.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.weight from d2v_model.modality_encoders.AUDIO.context_encoder.norm.weight in ckpt\n",
      "init param, map: modality_encoders.AUDIO.context_encoder.norm.bias from d2v_model.modality_encoders.AUDIO.context_encoder.norm.bias in ckpt\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.0.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.0.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.1.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.1.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.2.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.2.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.weight, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.blocks.3.0.bias, mapped: modality_encoders.AUDIO.decoder.blocks.3.0.bias\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.weight, mapped: modality_encoders.AUDIO.decoder.proj.weight\n",
      "Warning, miss key in ckpt: modality_encoders.AUDIO.decoder.proj.bias, mapped: modality_encoders.AUDIO.decoder.proj.bias\n",
      "init param, map: blocks.0.norm1.weight from d2v_model.blocks.0.norm1.weight in ckpt\n",
      "init param, map: blocks.0.norm1.bias from d2v_model.blocks.0.norm1.bias in ckpt\n",
      "init param, map: blocks.0.attn.qkv.weight from d2v_model.blocks.0.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.0.attn.qkv.bias from d2v_model.blocks.0.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.0.attn.proj.weight from d2v_model.blocks.0.attn.proj.weight in ckpt\n",
      "init param, map: blocks.0.attn.proj.bias from d2v_model.blocks.0.attn.proj.bias in ckpt\n",
      "init param, map: blocks.0.norm2.weight from d2v_model.blocks.0.norm2.weight in ckpt\n",
      "init param, map: blocks.0.norm2.bias from d2v_model.blocks.0.norm2.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.weight from d2v_model.blocks.0.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc1.bias from d2v_model.blocks.0.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.weight from d2v_model.blocks.0.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.0.mlp.fc2.bias from d2v_model.blocks.0.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.1.norm1.weight from d2v_model.blocks.1.norm1.weight in ckpt\n",
      "init param, map: blocks.1.norm1.bias from d2v_model.blocks.1.norm1.bias in ckpt\n",
      "init param, map: blocks.1.attn.qkv.weight from d2v_model.blocks.1.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.1.attn.qkv.bias from d2v_model.blocks.1.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.1.attn.proj.weight from d2v_model.blocks.1.attn.proj.weight in ckpt\n",
      "init param, map: blocks.1.attn.proj.bias from d2v_model.blocks.1.attn.proj.bias in ckpt\n",
      "init param, map: blocks.1.norm2.weight from d2v_model.blocks.1.norm2.weight in ckpt\n",
      "init param, map: blocks.1.norm2.bias from d2v_model.blocks.1.norm2.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.weight from d2v_model.blocks.1.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc1.bias from d2v_model.blocks.1.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.weight from d2v_model.blocks.1.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.1.mlp.fc2.bias from d2v_model.blocks.1.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.2.norm1.weight from d2v_model.blocks.2.norm1.weight in ckpt\n",
      "init param, map: blocks.2.norm1.bias from d2v_model.blocks.2.norm1.bias in ckpt\n",
      "init param, map: blocks.2.attn.qkv.weight from d2v_model.blocks.2.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.2.attn.qkv.bias from d2v_model.blocks.2.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.2.attn.proj.weight from d2v_model.blocks.2.attn.proj.weight in ckpt\n",
      "init param, map: blocks.2.attn.proj.bias from d2v_model.blocks.2.attn.proj.bias in ckpt\n",
      "init param, map: blocks.2.norm2.weight from d2v_model.blocks.2.norm2.weight in ckpt\n",
      "init param, map: blocks.2.norm2.bias from d2v_model.blocks.2.norm2.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.weight from d2v_model.blocks.2.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc1.bias from d2v_model.blocks.2.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.weight from d2v_model.blocks.2.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.2.mlp.fc2.bias from d2v_model.blocks.2.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.3.norm1.weight from d2v_model.blocks.3.norm1.weight in ckpt\n",
      "init param, map: blocks.3.norm1.bias from d2v_model.blocks.3.norm1.bias in ckpt\n",
      "init param, map: blocks.3.attn.qkv.weight from d2v_model.blocks.3.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.3.attn.qkv.bias from d2v_model.blocks.3.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.3.attn.proj.weight from d2v_model.blocks.3.attn.proj.weight in ckpt\n",
      "init param, map: blocks.3.attn.proj.bias from d2v_model.blocks.3.attn.proj.bias in ckpt\n",
      "init param, map: blocks.3.norm2.weight from d2v_model.blocks.3.norm2.weight in ckpt\n",
      "init param, map: blocks.3.norm2.bias from d2v_model.blocks.3.norm2.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.weight from d2v_model.blocks.3.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc1.bias from d2v_model.blocks.3.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.weight from d2v_model.blocks.3.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.3.mlp.fc2.bias from d2v_model.blocks.3.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.4.norm1.weight from d2v_model.blocks.4.norm1.weight in ckpt\n",
      "init param, map: blocks.4.norm1.bias from d2v_model.blocks.4.norm1.bias in ckpt\n",
      "init param, map: blocks.4.attn.qkv.weight from d2v_model.blocks.4.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.4.attn.qkv.bias from d2v_model.blocks.4.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.4.attn.proj.weight from d2v_model.blocks.4.attn.proj.weight in ckpt\n",
      "init param, map: blocks.4.attn.proj.bias from d2v_model.blocks.4.attn.proj.bias in ckpt\n",
      "init param, map: blocks.4.norm2.weight from d2v_model.blocks.4.norm2.weight in ckpt\n",
      "init param, map: blocks.4.norm2.bias from d2v_model.blocks.4.norm2.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.weight from d2v_model.blocks.4.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc1.bias from d2v_model.blocks.4.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.weight from d2v_model.blocks.4.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.4.mlp.fc2.bias from d2v_model.blocks.4.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.5.norm1.weight from d2v_model.blocks.5.norm1.weight in ckpt\n",
      "init param, map: blocks.5.norm1.bias from d2v_model.blocks.5.norm1.bias in ckpt\n",
      "init param, map: blocks.5.attn.qkv.weight from d2v_model.blocks.5.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.5.attn.qkv.bias from d2v_model.blocks.5.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.5.attn.proj.weight from d2v_model.blocks.5.attn.proj.weight in ckpt\n",
      "init param, map: blocks.5.attn.proj.bias from d2v_model.blocks.5.attn.proj.bias in ckpt\n",
      "init param, map: blocks.5.norm2.weight from d2v_model.blocks.5.norm2.weight in ckpt\n",
      "init param, map: blocks.5.norm2.bias from d2v_model.blocks.5.norm2.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.weight from d2v_model.blocks.5.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc1.bias from d2v_model.blocks.5.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.weight from d2v_model.blocks.5.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.5.mlp.fc2.bias from d2v_model.blocks.5.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.6.norm1.weight from d2v_model.blocks.6.norm1.weight in ckpt\n",
      "init param, map: blocks.6.norm1.bias from d2v_model.blocks.6.norm1.bias in ckpt\n",
      "init param, map: blocks.6.attn.qkv.weight from d2v_model.blocks.6.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.6.attn.qkv.bias from d2v_model.blocks.6.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.6.attn.proj.weight from d2v_model.blocks.6.attn.proj.weight in ckpt\n",
      "init param, map: blocks.6.attn.proj.bias from d2v_model.blocks.6.attn.proj.bias in ckpt\n",
      "init param, map: blocks.6.norm2.weight from d2v_model.blocks.6.norm2.weight in ckpt\n",
      "init param, map: blocks.6.norm2.bias from d2v_model.blocks.6.norm2.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.weight from d2v_model.blocks.6.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc1.bias from d2v_model.blocks.6.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.weight from d2v_model.blocks.6.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.6.mlp.fc2.bias from d2v_model.blocks.6.mlp.fc2.bias in ckpt\n",
      "init param, map: blocks.7.norm1.weight from d2v_model.blocks.7.norm1.weight in ckpt\n",
      "init param, map: blocks.7.norm1.bias from d2v_model.blocks.7.norm1.bias in ckpt\n",
      "init param, map: blocks.7.attn.qkv.weight from d2v_model.blocks.7.attn.qkv.weight in ckpt\n",
      "init param, map: blocks.7.attn.qkv.bias from d2v_model.blocks.7.attn.qkv.bias in ckpt\n",
      "init param, map: blocks.7.attn.proj.weight from d2v_model.blocks.7.attn.proj.weight in ckpt\n",
      "init param, map: blocks.7.attn.proj.bias from d2v_model.blocks.7.attn.proj.bias in ckpt\n",
      "init param, map: blocks.7.norm2.weight from d2v_model.blocks.7.norm2.weight in ckpt\n",
      "init param, map: blocks.7.norm2.bias from d2v_model.blocks.7.norm2.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.weight from d2v_model.blocks.7.mlp.fc1.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc1.bias from d2v_model.blocks.7.mlp.fc1.bias in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.weight from d2v_model.blocks.7.mlp.fc2.weight in ckpt\n",
      "init param, map: blocks.7.mlp.fc2.bias from d2v_model.blocks.7.mlp.fc2.bias in ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2501274/2523369789.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.a_rnn = torch.load(\"GRU.pt\")\n",
      "/home/naif/projects/videoEmotionRecognition/src/helpers.py:521: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f'{checkpoints_dir}/{loading_order[0]}_{model_name}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 12 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 15 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 13 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 15 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 14 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 15 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 14 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 15 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 13 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previously trained model weights state_dict loaded...\n",
      "Previously trained for 15 number of epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|███████████████████████████████| 24/24 [00:01<00:00, 20.93it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoints_loading_order = ['best', 'last']\n",
    "results =[]\n",
    "df = pd.read_csv(\"data/metadata.csv\")\n",
    "df = df[(df['dataset']=='UJ_ACTORS')].reset_index(drop=True)\n",
    "df['stratify_on']=df['dataset']+'_'+df['emotion']\n",
    "\n",
    "model = AuViLSTMModel(num_classes=8, mode= 'audio').cuda()\n",
    "\n",
    "loss_fn =lambda output,target: F.cross_entropy(output, target,label_smoothing=0.03)\n",
    "for fold in range(5):\n",
    "    current_seed = seed + fold\n",
    "    torch.manual_seed(current_seed)\n",
    "    np.random.seed(current_seed)\n",
    "    \n",
    "    # Split data\n",
    "    train_fold, valid_fold = train_test_split(\n",
    "        df, test_size=0.2,\n",
    "        stratify=df['stratify_on'],\n",
    "        random_state=current_seed\n",
    "    )\n",
    "\n",
    "    model_name = f\"audio_fold{fold}\"\n",
    "    load_model(model_name,model,loading_order=checkpoints_loading_order, checkpoints_dir=\"experiments/20241130_235623_sequential_training/model_checkpoints\")\n",
    "\n",
    "    valid_loader = create_dataloaders(df, batch_size=1 , valid_df=valid_fold)['valid'] # we will use only valid_df\n",
    "    loss, topk_auc =valid_one_epoch(valid_loader, model, loss_fn)\n",
    "    results.append([fold,\"best\", loss,topk_auc[0]])\n",
    "\n",
    "    load_model(model_name,model,loading_order=checkpoints_loading_order[::-1], checkpoints_dir=\"experiments/20241130_235623_sequential_training/model_checkpoints\")\n",
    "    valid_loader = create_dataloaders(df, batch_size=1 , valid_df=valid_fold)['valid'] # we will use only valid_df\n",
    "    loss, topk_auc =valid_one_epoch(valid_loader, model, loss_fn)\n",
    "    results.append([fold,\"last\", loss,topk_auc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 'best', 2.736377915988366, 33.333333333333336],\n",
       " [0, 'last', 2.7501519446571674, 33.333333333333336],\n",
       " [1, 'best', 2.8021961115300664, 33.333333333333336],\n",
       " [1, 'last', 2.8494909064223366, 37.5],\n",
       " [2, 'best', 2.4456141820798316, 33.333333333333336],\n",
       " [2, 'last', 2.574896389618516, 20.833333333333332],\n",
       " [3, 'best', 1.9726727865636349, 37.5],\n",
       " [3, 'last', 1.9777622874826193, 37.5],\n",
       " [4, 'best', 2.169513486325741, 37.5],\n",
       " [4, 'last', 2.184055851151546, 41.666666666666664]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "em2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
